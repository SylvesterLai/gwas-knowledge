----
title: "word_dump"
date: "2024-06-04"
----
GWAS Workflow
Collection of DNA and phenotypes
Pre GWAS (QC)
GWAS
Meta-Analysis
Post-GWAS
Pre-GWAS (QC)
Download Data Set
You need .bed, .bim, and .fam files.
Data Formats
 
FASTQ
Raw Genome Data from WGS.
.sam/.bam
Mapped FASTQ Data
.fam/.bim/.bed PLINK
.fam/.bim/.bed from SNP Array. Format is PLINK compatible.
.fam/.psam
Individual information
.map/.bim/.pvar
Variant Information containing SNPs.
.bgen/.pgen/.bed
Format Conversion from .vcf files
Combination of individual information and variant information
.vcf/.vcf.gz/.vcf.gz.tbi
Genotype Calling of .sam/.bam from WGS
Genotype Calling of .fam/.bim/.bed from SNP Array
.bgen/.bgi
Imputation Summary
.pgen/.psam/.pwar
PLINK2 format
Summary
 
Reference Data Formats

Data Quality Check
QC Step	PLINK command	Common Thresholds
Sample Missing Rate	--geno, --missing	>0.01, 0.02 or 0.05
SNP Missing Rate	--mind, --missing	>0.01, 0.02 or 0.05
Minor Allele Frequency	--freq, --maf	maf < 0.01
Sample Relatedness	--genome	pi_hat > 0.2
Hardy-Weinberg Eq	--hwe, --hardy	hwe < 1e-06
LD Pruning	--indep-pairwise x y z	Window x = 50
Window shift y = 5
Correlation thresholdz=0.2
Inbreeding F coefficient	--het	Outside 3sd from mean
PLINK Command Format
 
You can have the same input file prefix and output file prefix.
Missing Rate
Sample Missing Rate
Sample Missing Rate – proportion of missing values for an individual across all SNPs
Output – {output_prefix}.imiss
 
SNP Missing Rate
SNP Missing Rate - proportion of missing values for a SNP across all samples
Output – {output_prefix).lmiss
 
Minor Allele Frequency
REF and ALT is arbitrarily determined. 
PLINK 1.9 uses A1 (minor) and A2 (major). 
PLINK 2 uses REF and ALT. Anyone of them can be the minor/major allele.
 
MAF Thresholds
	Common variants : MAF>=0.05
	Low-frequency variants : 0.01<=MAF<0.05
	Rare variants : MAF<0.01
Hardy-Weinberg Equilibrium
 
QC Filter
For example:
	--maf 0.01 : exclude snps with maf<0.01
	--geno 0.02 :filters out all variants with missing rates exceeding 0.02
	--mind 0.02 :filters out all samples with missing rates exceeding 0.02
	--hwe 1e-6 : filters out all variants which have Hardy-Weinberg equilibrium exact test p-value below the provided threshold
Linkage Disequilibrium Pruning

plink \
    --bfile ${genotypeFile} \
    --maf 0.01 \
    --geno 0.02 \
    --mind 0.02 \
    --hwe 1e-6 \
    --indep-pairwise 50 5 0.2 \
    --out plink_results
Output is {output_prefix}.prune.in and {output_prefix}.prune.out
Inbreeding F coefficient
Higher chance of homozygosity if inbred compared to normal. Inbreeding is excess of expected homozygotes over total number of observed genotypes – expected homozygotes.
Calculated for each individual.
Contamination/outbreeding comes when O(HOM) < E(HOM), causing F to be negative.
 
plink \
    --bfile ${genotypeFile} \
    --extract plink_results.prune.in \
    --het \
    --out plink_results
Output is {output_prefix}.het
Sample and SNP filtering

Sample
--keep and –remove to select or exclude samples
Input is filename of sample FID/IID file
SNPs
--extract and --exclude to select or exclude samples
Input is filename of SNP list file
Kinship coefficient
Kinship calculates how similar each pair of individuals’ genomes are. If too close, suggests relatedness and needs to be removed.
Prune the data first. Calculated for each pair of individuals.
Can run for PLINK1.9 using --genome and PLINK2 using --make-king. KING provides a triangular matrix with diagonal elements removed. KING is more robust when there is population substructure and should be used if possible.
plink2 --bfile sample_data.clean --make-king --out sample_data.clean

Output – {output_prefix}.king and {output_prefix}.king.id
King.id gives the columns/row for the triangular matrix.
LD Calculation
Not sure why need to calculate LD again after LD pruning, but here it is.
Can use --chr to narrow down to specific chromosomes.
plink \
        --bfile ${genotypeFile} \
        --chr 22 \
        --r2 \
        --out plink_results
Pruning vs Clumping
Pruning: it uses the first SNP (in genome order) and computes the correlation with the following ones (e.g. 50). When it finds a large correlation, it removes one SNP from the correlated pair, keeping the one with the largest minor allele frequency (MAF), thus possibly removing the first SNP. Then it goes on with the next SNP (not yet removed). So, in some worst case scenario, this algorithm may in fact remove all SNPs of the genome (except one).
Clumping; it uses some statistic (usually p-value in the case of GWAS/PRS) to sort the SNPs by importance (e.g. keeping the most significant ones). It takes the first one (e.g. most significant SNP) and removes SNPs that are too correlated with this one in a window around it. As opposed to pruning, this procedure makes sure that this SNP is never removed, keeping at least one representative SNP by region of the genome. Then it goes on with the next most significant SNP that has not been removed yet. In the case of computing principal components, there is no p-value available, so I propose to use the MAF instead as the statistic to rank SNPs (in decreasing order). Using MAFs makes clumping very similar to pruning, but without any worst-case scenario.
In Polygenic Score Analysis, Clumping is preferred. If you want to compute PCA, then Pruning is preferred. Pruning uses r^2 value and keeps the one with highest MAF. Clumping uses p-value. Pruning of MAF can be done using clumping algorithms too.
https://github.com/privefl/bigsnpr?tab=readme-ov-file 
Conversion of data formats
Bed/bim/fam <-> ped/map
 
#extract the 1000 samples with the pruned SNPs, and make a bed file.
plink \
    --bfile ${genotypeFile} \
    --extract plink_results.prune.in \
    --make-bed \
    --out plink_1000_pruned

#convert the bed/bim/fam to ped/map
plink \
        --bfile plink_1000_pruned \
        --recode \
        --out plink_1000_pruned
Sample code for clean dataset
plink \
        --bfile ${genotypeFile} \
        --maf 0.01 \
        --geno 0.02 \
        --mind 0.02 \
        --hwe 1e-6 \
        --remove high_het.sample \
        --keep-allele-order \
        --make-bed \
        --out sample_data.clean
Additional Steps
Check sex
https://www.cog-genomics.org/plink/1.9/basic_stats#check_sex 
Case/control nonrandom missingness test
https://www.cog-genomics.org/plink/1.9/assoc#test_missing 
PCA Preparation
PCA is used to look for ancestry differences in the sample individuals.
Exclude SNPs in high LD or HLA region
Exclude SNPs in high LD or HLA regions, to reduce over-representation of these regions in the PCA results
Reason - Long-range LD can confound genome scans in admixed populations. American journal of human genetics, 83(1), 132–139. https://doi.org/10.1016/j.ajhg.2008.06.005 
HLA regions are prone to many changes, and have high LD and diversity. They could overpower the PCA results.
Download BED like files for high LD or HLA regions
https://genome.sph.umich.edu/wiki/Regions_of_high_linkage_disequilibrium_(LD) 
Convert BED file to list of SNPs
plink \
    --bfile ${plinkFile} \
    --make-set high-ld-hg19.txt \
    --write-set \
    --out hild
After that, we can just use --exclude hild.set to remove them.
PCA Analysis 
Steps
	LD-Pruning (https://www.cog-genomics.org/plink/2.0/ld#indep)
	Removing relatives from calculating PCs (usually 2-degree) (https://www.cog-genomics.org/plink/2.0/distance#king_cutoff)
	Running PCA using un-related samples and independent SNPs (https://www.cog-genomics.org/plink/2.0/strat#pca)
	Projecting to all samples (https://www.cog-genomics.org/plink/2.0/score#pca_project)
Sample Code
plinkFile="" #please set this to your own path
outPrefix="plink_results"
threadnum=2
hildset = hild.set 

# LD-pruning, excluding high-LD and HLA regions
plink2 \
        --bfile ${plinkFile} \
        --maf 0.01 \
        --threads ${threadnum} \
        --exclude ${hildset} \ 
        --indep-pairwise 500 50 0.2 \
        --out ${outPrefix}

# Remove related samples using king-cuttoff
plink2 \
        --bfile ${plinkFile} \
        --extract ${outPrefix}.prune.in \
        --king-cutoff 0.0884 \
        --threads ${threadnum} \
        --out ${outPrefix}

# PCA after pruning and removing related samples
plink2 \
        --bfile ${plinkFile} \
        --keep ${outPrefix}.king.cutoff.in.id \
        --extract ${outPrefix}.prune.in \
        --freq counts \
        --threads ${threadnum} \
        --pca approx allele-wts 10 \     
        --out ${outPrefix}

# Projection (related and unrelated samples)
plink2 \
        --bfile ${plinkFile} \
        --threads ${threadnum} \
        --read-freq ${outPrefix}.acount \
        --score ${outPrefix}.eigenvec.allele 2 5 header-read no-mean-imputation variance-standardize \
        --score-col-nums 6-15 \
        --out ${outPrefix}_projected
--pca approx is recommended when you have >5000 samples. Else, --pca is enough. The 10 tells the program to get the top 10 PCs.
Score {output_prefix}.eigenvec.allele 2 5 sets 
Output
{output_prefix}.eigenvec.allele – PC of alleles
{output_prefix}.acount – allele count
Phasing (Pre-Imputation)
Phasing is a pre-step of imputation. Phasing determines haplotypes, which are groups of alleles that are inherited together. The output is a haplotype .hap file. You can use several tools available to do the phasing.
Imputation (server)
Imputation using TOPMed or Michigan server.
Liftover (converting genomic coordinates between reference builds), phasing, and QC is done automatically.

Imputation (manual)
Using minimac4.
minimac4 \
  --refHaps ./phased_reference.m3vcf \
  --haps ./phased_target.vcf.gz \
  --prefix ./result \
  --format GT,DS,HDS,GP,SD \
  --meta \
  --log \
  --cpus 10
refHaps – reference haplotypes
haps – target haplotypes
format -  
	GT - Estimated most likely genotype.
	DS - Estimated alternate allele dosage [P(0/1)+2*P(1/1)].
	HDS - Estimated phased haploid alternate allele dosage.
	GP - Estimated Posterior Genotype Probabilities P(0/0), P(0/1) and P(1/1).
	SD - Estimated Variance of Posterior Genotype Probabilities.
https://genome.sph.umich.edu/wiki/Minimac4_Documentation 
GWAS

Genetic Models
3 main models, Dominant, Recessive, and Additive. Let A be REF and G be ALT.
Genetic Models	AA	AG	GG
Additive	0	1	2
Dominant	0	1	1
Recessive	0	0	1

Association test for the genetic models
Genotype	AA	AG	GG	Total
Case	800	400	800	2000
Control	1000	500	500	2000
Total	1800	900	1300	4000

Dominant Model
Chi-square test
Genotype	Control: AA	Case: AG/GG	Total
Case	800	1200	2000
Control	1000	1000	2000
Total	1800	2200	4000

Recessive Model
Chi-square test
Genotype	Control: AA/AG	Case: GG	Total
Case	1200	800	2000
Control	1500	500	2000
Total	2700	1300	4000

Additive Model
Cochran-Armitage Trend Test
Alt Allele Count	0	1	2	Total
Case	800	400	800	2000
Control	1000	500	500	2000
Total	1800	900	1300	4000

Linear Models for GWAS
PLINK can run linear models. The following equation can be converted to logit for binary traits.
y=Gβ_G+Xβ_X+e
G is the genotype matrix
B_G is the effect size for variants.
X and B_X are covariates and their effects.
e is the error term.
File Preparation
Genotype file – PLINK, VCF or BGEN format
Phenotype file – text file
Covariate file(optional) – text file. Use top PCs from PCA
PLINK Association test
Firth correction adds a penalty term to the log-likelihood function when fitting logistic model. For quantitative traits, linear regression will be used, so firth is not applicable. 
Sample Code
genotypeFile="../04_Data_QC/sample_data.clean" # the clean dataset we generated in previous section
phenotypeFile="../01_Dataset/1kgeas_binary.txt" # the phenotype file
covariateFile="../05_PCA/plink_results_projected.sscore" # the PC score file

covariateCols=6-10
colName="B1"
threadnum=2

plink2 \
    --bfile ${genotypeFile} \
    --pheno ${phenotypeFile} \
    --pheno-name ${colName} \
    --maf 0.01 \
    --covar ${covariateFile} \
    --covar-col-nums ${covariateCols} \
    --glm hide-covar firth  firth-residualize single-prec-cc \
    --threads ${threadnum} \
    --out 1kgeas
Additional Steps
Kinship pruning (as linear regression ignores relatedness) using --keep xxx/kiso2021/for_plink2/unrelated.sample.id
Use only variants that pass a MaCH Rsq filter using --mach-r2-filter 0.7 2.0
>0.3 to 0.5 is sufficient threshold. MaCH r^2 is the squared correlation between imputed genotype and true underlying genotype (~Imputation Quality). NOTE: When pgen file is used, the upper boundary should be 2.
Include more columns in the summary stats using --glm cols=+a1freq,+machr2 firth-fallback omit-ref
>cols= will include the columns in sumstats
>firth-fallback will test common variants without firth correction (to improve the speed)
>omit-ref will force ALT == A1 == effect allele, otherwise the minor allele will be tested which may be REF allele
Normalize the covariates using --covar-variance-standardize
Specify column name instead of column index using --covar-name AGE SEX PC1-PC20
Genomic Control
Genomic control is a way to control for confounding factors including population stratification. The way to do it is to calculate λ and then use it to adjust chi-square statistics, similar to Bonferroni correction.
λ = median(observed χ^2) / 0.456
χ^2_adjusted = χ^2_observed / λ
And then, finally, re-calculate p values using adjusted chi-square value.
Visualization using gwaslab (python)
https://cloufield.github.io/GWASTutorial/Visualization/ 
Main points – Manhattan plot, QQ plot, Regional plot
Manhattan Plot
QQ Plot
 
Regional Plot (with annotation)
 
Regional Plot (with LD information)
 
Standardized sumstats format (GWAS-SSF)
Standard format in GWAS catalog, consisting of
	Tab separated file with well-defined fields
	Metadata file describing the study (such as sample ancestry, genotyping method, md5sum etc)
 
Linear Mixed Models
	Gcta64
	GEMMA
	BOLT-LMM
	FastLMM
Regenie (2 step Residual LMM)
Regenie does a linear regression model based on residuals in a two step approach.
	Fit a null model to the phenotype data without the SNPs of interest, including covariates and relatedness. This model will account for covariates and relatedness/population structure, with ridge regression.
y=Xβ+Zγ+ϵ
X is covariates
Beta is covariates effect size.
Z is matrix of genetic data (used to capture relatedness)
Gamma is effect size of genetic data

	The residues from step 1 are calculated using Residual =y-y ̂ and tested for association using a simple linear regression model.
Residual=α+SNP ∙β+ϵ
Alpha is the intercept term, which is the expected value of phenotype when SNP genotype is zero.
Post-GWAS



Variant annotation
Maps the variant to genomic features(position of variant relative to gene, regulatory elements and splicing sites). Several tools available, we will use ANNOVAR.

ANNOVAR
ANNOVAR requires the downloading of reference genomes and annotations.
Format input file
awk 'NR>1 && NR<100000 {print $1,$2,$2,$4,$5}' ../06_Association_tests/1kgeas.B1.glm.logistic.    hybrid > annovar_input.txt
Annotation
Can use -vcfinput to accept vcf files.
input=annovar_input.txt
humandb=/home/he/tools/annovar/annovar/humandb
table_annovar.pl ${input} ${humandb} -buildver hg19 -out myannotation -remove -protocol refGene     -operation g -nastring . -polish
Annotation (Multiple databases)
# input file is in vcf format
table_annovar.pl \
  ${in_vcf} \
  ${humandb} \
  -buildver hg19 \
  -protocol refGene,avsnp150,clinvar_20200316,gnomad211_exome \
  -operation g,f,f,f \
  -remove \
  -out ${out_prefix} \ 
  -vcfinput
VEP
Annotation can also use done using VEP but the website is lagging.
https://www.ensembl.org/vep 
GCTA-GREML

Narrow-sense heritability
Phenotypes are affected by 4 types of variance. For narrow sense heritability, we focus on additive genetic variance.
	Additive genetic variance – Variance due to the sum of effects of individual allels
	Dominance variance - Variance due to interaction between alleles at same locus
	Epistatic variance - Variance due to interaction between alleles at different loci
	Environmental variance - Variance due to environmental factors
Narrow sense heritability is the ratio of additive genetic variance to total phenotypic variance.
Genetic Relationship Matrix (GRM)
GRM measures the genetic relatedness between individuals. Calculation example below
Person	SNP1	SNP2	SNP3
A	0	1	2
B	1	1	1
C	2	0	0

Calculate Allele Frequencies p_j:-
SNP1 Frequency of Minor Allele = (0+1+2)/(3x2) = 0.5
SNP2 Frequency of Minor Allele = (1+1+0)/(3x2) = 0.33
SNP3 Frequency of Minor Allele = (2+1+0)/(3x2) = 0.5
Standardize Genotypes for person i and SNP j:-
z_ij=(g_ij-2p_j)/√(2p_j (1-p_j ) )
For SNP1:
z_(A,SNP_1 )=(0-2×0.5)/√(2×0.5×(1-0.5))=-1
z_(A,SNP_3 )=(2-2×0.5)/√(2×0.5×(1-0.5) )=1
Construct the GRM for M SNPs:
G=1/M ∑_(j=1)^M▒〖z_j z_j^T 〗
Meta Analysis
QC has to be the same.
Meta Analysis is performed on summary statistics.

Issues
How to determine discovery and replication cohort? Replication cohort must be independent from discovery cohort, with no shared individuals or genetic relationships between both cohorts.
Mendelian Randomization is to treat genes like randomized trials and then infer causality.

